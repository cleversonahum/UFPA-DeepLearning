{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.17.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy torch matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN class for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, nhiddenLayers, hiddenNeurons):\n",
    "        super(linearRegression, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        for i in range(0,nhiddenLayers): # adding hidden layers\n",
    "            if(i==0): #Input layer\n",
    "                layers.append(torch.nn.Linear(inputSize, hiddenNeurons))\n",
    "                layers.append(torch.nn.ReLU())\n",
    "            else:\n",
    "                layers.append(torch.nn.BatchNorm1d(hiddenNeurons))\n",
    "                layers.append(torch.nn.Linear(hiddenNeurons, hiddenNeurons))\n",
    "                layers.append(torch.nn.ReLU())\n",
    "\n",
    "        layers.append(torch.nn.Linear(hiddenNeurons, outputSize)) # output layer\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "        print(\"\\nNetwork Architecture: \\n\", self.model,\"\\n\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001\n",
    "momentum = 0.9 \n",
    "epochs = 200 # Original Value is 2000\n",
    "batch_size = 3000\n",
    "train_set = 60000\n",
    "test_set = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda x: 2 * (x ** 2) - 1\n",
    "func = lambda x: f1(f1(np.cos(x)))\n",
    "x = torch.unsqueeze(torch.FloatTensor(train_set+test_set).uniform_(-2*pi, 2*pi), dim=1)\n",
    "y = func(x)\n",
    "\n",
    "# Train Dataset and making generator for mini-batches\n",
    "train_x = x[0:train_set]\n",
    "train_y = y[0:train_set]\n",
    "train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test Dataset\n",
    "test_x = x[train_set:(train_set+test_set)]\n",
    "test_y = y[train_set:(train_set+test_set)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestNet(arch:tuple) -> torch.tensor:\n",
    "    \n",
    "    # Defining network architecture\n",
    "    print(\"Hidden Layers Quantity: \",arch[0],\",  Units per Layer: \",arch[1],\"\\n\")\n",
    "    net = linearRegression(1, 1, arch[0], arch[1]) # Defining network architecture where arch[1] corresponds to the layer number and arch[2] to the number of units in a hidden layer\n",
    "    criterion = torch.nn.MSELoss() # Define criterion to evaluate the network, in this case MSE\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learningRate, momentum=momentum) # optimizer used is SGD\n",
    "        \n",
    "    # Training the network\n",
    "    print(\"Training Results: \")\n",
    "    for epoch in range(1,epochs+1): # Iteration in each epoch\n",
    "        for step, (t_x, t_y) in enumerate(train_loader): # Iterating in each mini-batch\n",
    "            optimizer.zero_grad() # Removing buffer from previous epochs\n",
    "            outputs = net(t_x) # Output training into the model\n",
    "            loss = criterion(outputs, t_y) # Get loss for predicted outputs\n",
    "            if((epoch%100==0) and step == train_set/batch_size-1): #Print Train results for each 100 epochs\n",
    "                print(\"Epoch: \", epoch,\"  Step: \", step,\"  Loss: \", loss)\n",
    "            loss.backward() # Propagate the loss\n",
    "            optimizer.step() # Update parameters\n",
    "            \n",
    "    # Evaluating the network using the test dataset\n",
    "    print(\"\\n\\nEvaluation over test dataset:\")\n",
    "    test_outputs = net(test_x) # Generating network outputs for test data\n",
    "    mean_test_error = torch.sqrt(criterion(test_outputs, test_y)) # Calculating RMSE over the predicted data\n",
    "    print(\"Mean Test Error: \", mean_test_error, \"\\n\\n\\n\\n\")\n",
    "    \n",
    "    return mean_test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers Quantity:  3 ,  Units per Layer:  24 \n",
      "\n",
      "\n",
      "Network Architecture: \n",
      " Sequential(\n",
      "  (0): Linear(in_features=1, out_features=24, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Linear(in_features=24, out_features=24, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): Linear(in_features=24, out_features=24, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=24, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "Training Results: \n",
      "Epoch:  100   Step:  19   Loss:  tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "Epoch:  200   Step:  19   Loss:  tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "\n",
      "\n",
      "Evaluation over test dataset:\n",
      "Mean Test Error:  tensor(0.0782, grad_fn=<SqrtBackward>) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor(0.0782, grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "result = trainTestNet((3,24))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
