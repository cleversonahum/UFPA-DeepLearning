{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.17.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy torch matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN class for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, nhiddenLayers, hiddenNeurons):\n",
    "        super(linearRegression, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        for i in range(0,nhiddenLayers): # adding hidden layers\n",
    "            if(i==0): #Input layer\n",
    "                layers.append(torch.nn.Linear(inputSize, hiddenNeurons))\n",
    "                layers.append(torch.nn.ReLU())\n",
    "            else:\n",
    "                layers.append(torch.nn.BatchNorm1d(hiddenNeurons))\n",
    "                layers.append(torch.nn.Linear(hiddenNeurons, hiddenNeurons))\n",
    "                layers.append(torch.nn.ReLU())\n",
    "\n",
    "        layers.append(torch.nn.Linear(hiddenNeurons, outputSize)) # output layer\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "        print(self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001\n",
    "momentum = 0.9 \n",
    "epochs = 200 # Original Value is 2000\n",
    "batch_size = 3000\n",
    "train_set = 60000\n",
    "test_set = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda x: 2 * (x ** 2) - 1\n",
    "func = lambda x: f1(f1(np.cos(x)))\n",
    "x = torch.unsqueeze(torch.FloatTensor(train_set+test_set).uniform_(-2*pi, 2*pi), dim=1)\n",
    "y = func(x)\n",
    "\n",
    "# Train Dataset and making generator for mini-batches\n",
    "train_x = x[0:train_set]\n",
    "train_y = y[0:train_set]\n",
    "train_dataset = Data.TensorDataset(train_x, train_y)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test Dataset\n",
    "test_x = x[train_set:(train_set+test_set)]\n",
    "test_y = y[train_set:(train_set+test_set)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Net, Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=24, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Linear(in_features=24, out_features=24, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): Linear(in_features=24, out_features=24, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=24, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = linearRegression(1,1,3, 24)\n",
    "criterion = torch.nn.MSELoss() # Define criterion to evaluate the network\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learningRate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   Step:  19   Loss:  tensor(0.5150, grad_fn=<MseLossBackward>)\n",
      "Epoch:  10   Step:  19   Loss:  tensor(0.4413, grad_fn=<MseLossBackward>)\n",
      "Epoch:  20   Step:  19   Loss:  tensor(0.3526, grad_fn=<MseLossBackward>)\n",
      "Epoch:  30   Step:  19   Loss:  tensor(0.3101, grad_fn=<MseLossBackward>)\n",
      "Epoch:  40   Step:  19   Loss:  tensor(0.2691, grad_fn=<MseLossBackward>)\n",
      "Epoch:  50   Step:  19   Loss:  tensor(0.1721, grad_fn=<MseLossBackward>)\n",
      "Epoch:  60   Step:  19   Loss:  tensor(0.1354, grad_fn=<MseLossBackward>)\n",
      "Epoch:  70   Step:  19   Loss:  tensor(0.0913, grad_fn=<MseLossBackward>)\n",
      "Epoch:  80   Step:  19   Loss:  tensor(0.0744, grad_fn=<MseLossBackward>)\n",
      "Epoch:  90   Step:  19   Loss:  tensor(0.0825, grad_fn=<MseLossBackward>)\n",
      "Epoch:  100   Step:  19   Loss:  tensor(0.0657, grad_fn=<MseLossBackward>)\n",
      "Epoch:  110   Step:  19   Loss:  tensor(0.0395, grad_fn=<MseLossBackward>)\n",
      "Epoch:  120   Step:  19   Loss:  tensor(0.0503, grad_fn=<MseLossBackward>)\n",
      "Epoch:  130   Step:  19   Loss:  tensor(0.0474, grad_fn=<MseLossBackward>)\n",
      "Epoch:  140   Step:  19   Loss:  tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "Epoch:  150   Step:  19   Loss:  tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "Epoch:  160   Step:  19   Loss:  tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "Epoch:  170   Step:  19   Loss:  tensor(0.0391, grad_fn=<MseLossBackward>)\n",
      "Epoch:  180   Step:  19   Loss:  tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "Epoch:  190   Step:  19   Loss:  tensor(0.0210, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): # Iteration in each epoch\n",
    "    for step, (t_x, t_y) in enumerate(train_loader): # Iterating in each batch\n",
    "        optimizer.zero_grad() # Removing buffer from previous epochs\n",
    "        outputs = net(t_x) # Output training into the model\n",
    "        loss = criterion(outputs, t_y) # Get loss for predicted outputs\n",
    "        if(epoch%10 == 0 and step == train_set/batch_size-1):\n",
    "            print(\"Epoch: \", epoch,\"  Step: \", step,\"  Loss: \", loss)\n",
    "        loss.backward() # Propagate the loss\n",
    "        optimizer.step() # Update parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Error:  tensor(0.1597, grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "test_outputs = net(test_x) # Generating network outputs for test data\n",
    "mean_test_error = torch.sqrt(criterion(test_outputs, test_y)) # Calculating RMSE over the predicted data\n",
    "print(\"Mean Test Error: \", mean_test_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
